from src.config.settings import (
    openai_client, 
    ENABLE_INPUT_MODERATION, 
    ENABLE_TOPIC_VALIDATION, 
    ENABLE_OUTPUT_MODERATION
)
import asyncio

class GuardrailsService:
    def __init__(self):
        self.respuestas_rechazo = {
            "tema_fuera_alcance": (
                "Perdon, no puedo ayudarte con eso, me especializo unicamente "
                "en temas de seguridad contra incendios"
            ),
            "lenguaje_inapropiado": (
                "Por favor, mantengamos una conversaci√≥n respetuosa. "
                "Estoy aqu√≠ para ayudarte con consultas sobre seguridad contra incendios. üôè"
            ),
            "tema_y_lenguaje": (
                "Por favor, mantengamos una conversaci√≥n respetuosa sobre temas relacionados "
                "con seguridad contra incendios. ¬øEn qu√© puedo ayudarte? üòä"
            )
        }
    
    def validar_contenido_inapropiado(self, texto: str) -> dict:
        """Usa OpenAI Moderation API para detectar contenido inapropiado"""
        try:
            response = openai_client.moderations.create(input=texto)
            result = response.results[0]
            
            if result.flagged:
                print(f"üö´ Contenido inapropiado detectado: {result.categories}")
                return {
                    "es_valido": False,
                    "respuesta_rechazo": self.respuestas_rechazo["lenguaje_inapropiado"],
                    "razon": "contenido_inapropiado",
                    "categorias": [cat for cat, flagged in result.categories if flagged]
                }
            
            print("‚úÖ Contenido apropiado seg√∫n OpenAI Moderation")
            return {"es_valido": True}
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error en OpenAI Moderation: {e}")
            # Fallback: continuar sin bloquear
            return {"es_valido": True}
    
    def validar_tema_con_llm(self, mensaje: str) -> dict:
        """Valida si el mensaje est√° relacionado con seguridad contra incendios usando LLM"""
        try:
            prompt = f"""Eres un validador para Argenfuego, empresa especializada en seguridad contra incendios.

SERVICIOS DE ARGENFUEGO:
- Venta de matafuegos/extintores y elementos de protecci√≥n personal
- Mantenimiento y recarga de extintores
- Control anual e inspecciones de sistemas contra incendios
- Instalaci√≥n de redes de incendio y sistemas fijos
- Habilitaciones y certificaciones de seguridad
- Asesoramiento y capacitaci√≥n en prevenci√≥n de incendios

Responde SOLO 'S√ç' si el mensaje est√° relacionado con:
- Cualquier consulta sobre nuestros servicios/productos
- Preguntas t√©cnicas sobre seguridad contra incendios
- Consultas de ventas, precios, mantenimiento
- Saludos y conversaci√≥n b√°sica de atenci√≥n al cliente
- Solicitudes de informaci√≥n o asesoramiento

Responde 'NO' solo para temas COMPLETAMENTE ajenos (deportes, pol√≠tica, cocina, etc.)

Mensaje del cliente: "{mensaje}"

Respuesta:"""
            
            response = openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=5,
                temperature=0.2
            )
            
            respuesta = response.choices[0].message.content.lower().strip()
            es_tema_valido = "s√≠" in respuesta or "si" in respuesta
            
            if not es_tema_valido:
                print(f"üö´ Tema fuera de alcance: {mensaje[:50]}...")
                return {
                    "es_valido": False,
                    "respuesta_rechazo": self.respuestas_rechazo["tema_fuera_alcance"],
                    "razon": "tema_fuera_alcance"
                }
            
            print("‚úÖ Tema v√°lido seg√∫n LLM")
            return {"es_valido": True}
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error en validaci√≥n de tema: {e}")
            # Fallback: permitir el mensaje
            return {"es_valido": True}
    
    def validar_input(self, mensaje: str) -> dict:
        """Valida el input del usuario con configuraci√≥n din√°mica de guardrails"""
        print(f"üîß Guardrails config: INPUT_MOD={ENABLE_INPUT_MODERATION}, TOPIC={ENABLE_TOPIC_VALIDATION}")
        
        # Nivel 1: Contenido inapropiado (condicional)
        if ENABLE_INPUT_MODERATION:
            validacion_contenido = self.validar_contenido_inapropiado(mensaje)
            if not validacion_contenido["es_valido"]:
                return validacion_contenido
        else:
            print("‚è≠Ô∏è Saltando OpenAI Moderation (deshabilitado)")
        
        # Nivel 2: Validaci√≥n de tema (condicional)
        if ENABLE_TOPIC_VALIDATION:
            validacion_tema = self.validar_tema_con_llm(mensaje)
            if not validacion_tema["es_valido"]:
                return validacion_tema
        else:
            print("‚è≠Ô∏è Saltando validaci√≥n de tema (deshabilitado)")
        
        print("‚úÖ Mensaje aprobado por guardrails configurables")
        return {"es_valido": True}
    
    def validar_output(self, respuesta: str) -> dict:
        """Valida la respuesta del chatbot con configuraci√≥n din√°mica"""
        if not ENABLE_OUTPUT_MODERATION:
            print("‚è≠Ô∏è Saltando validaci√≥n de output (deshabilitado)")
            return {"es_valido": True, "respuesta": respuesta}
            
        print("üîç Validando output del chatbot...")
        validacion = self.validar_contenido_inapropiado(respuesta)
        
        if not validacion["es_valido"]:
            print("üö´ Respuesta del chatbot rechazada por contenido inapropiado")
            return {
                "es_valido": False,
                "respuesta_fallback": (
                    "Disculpa, hubo un problema procesando tu consulta. "
                    "¬øPodr√≠as reformular tu pregunta sobre seguridad contra incendios? üî•"
                )
            }
        
        print("‚úÖ Respuesta del chatbot aprobada")
        return {"es_valido": True, "respuesta": respuesta}

    async def log_conversation_async(self, user_id: str, mensaje: str, respuesta: str, metadata: dict = None):
        """Log conversaciones de manera async sin impactar latencia"""
        try:
            # TODO: Implementar logging real (archivo, base de datos, etc.)
            log_data = {
                "timestamp": asyncio.get_event_loop().time(),
                "user_id": user_id,
                "input": mensaje,
                "output": respuesta,
                "metadata": metadata or {}
            }
            print(f"üìà [ASYNC LOG] {user_id}: {mensaje[:30]}... -> {respuesta[:30]}...")
        except Exception as e:
            print(f"‚ö†Ô∏è Error en logging async: {e}")

guardrails_service = GuardrailsService()